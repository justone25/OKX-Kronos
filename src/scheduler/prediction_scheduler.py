"""
æŒç»­é¢„æµ‹è°ƒåº¦å™¨
æ”¯æŒå®šæ—¶é‡‡æ ·ã€é¢„æµ‹æ›´æ–°å’Œç»“æžœå­˜å‚¨
æ”¯æŒSQLiteå’ŒPostgreSQLæ•°æ®åº“
"""
import time
import logging
import threading
import json
import os
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from pathlib import Path
import pandas as pd
import schedule

from ..trading.prediction_service import PredictionService
from ..utils.config import OKXConfig, TradingConfig
from ..utils.database import db_config, get_db_connection, execute_query, init_database


class PredictionScheduler:
    """æŒç»­é¢„æµ‹è°ƒåº¦å™¨"""
    
    def __init__(self, okx_config: OKXConfig, trading_config: TradingConfig,
                 db_path: str = None, device: str = "cpu"):
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨

        Args:
            okx_config: OKX APIé…ç½®
            trading_config: äº¤æ˜“é…ç½®
            db_path: æ•°æ®åº“è·¯å¾„ (å¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨DATABASE_URLçŽ¯å¢ƒå˜é‡)
            device: è®¡ç®—è®¾å¤‡
        """
        self.logger = logging.getLogger(__name__)
        self.okx_config = okx_config
        self.trading_config = trading_config
        self.device = device

        # æ•°æ®åº“é…ç½®
        if db_path and not os.getenv('DATABASE_URL'):
            # å¦‚æžœæä¾›äº†db_pathä¸”æ²¡æœ‰DATABASE_URLï¼Œè®¾ç½®SQLiteè·¯å¾„
            os.environ['SQLITE_DB_PATH'] = str(Path(db_path).absolute())
            # åˆ›å»ºæ•°æ®ç›®å½•
            Path(db_path).parent.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–é¢„æµ‹æœåŠ¡
        self.prediction_service = PredictionService(okx_config, trading_config, device)

        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()

        # è¿è¡ŒçŠ¶æ€
        self.is_running = False
        self.scheduler_thread = None
        
        # é…ç½®å‚æ•°
        self.prediction_interval = 10  # é¢„æµ‹é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
        self.lookback_hours = 48      # å›žçœ‹å°æ—¶æ•°
        self.pred_hours = 2           # é¢„æµ‹å°æ—¶æ•°
        self.temperature = 0.8        # é‡‡æ ·æ¸©åº¦
        self.top_p = 0.9             # nucleusé‡‡æ ·å‚æ•°
        self.sample_count = 3        # é‡‡æ ·æ¬¡æ•°
        
        
        self.logger.info("âœ… é¢„æµ‹è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            init_database()
            self.logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def save_prediction(self, report: Dict[str, Any]):
        """ä¿å­˜é¢„æµ‹ç»“æžœåˆ°æ•°æ®åº“"""
        try:
            stats = report['statistics']
            params = report['parameters']

            # èŽ·å–é¢„æµ‹æ•°æ®
            prediction_df = report.get('prediction_data', None)

            # è®¡ç®—é¢„æµ‹çš„é«˜ä½Žä»·
            predicted_high = stats.get('predicted_price_end', 0)
            predicted_low = stats.get('predicted_price_end', 0)

            if prediction_df is not None and not prediction_df.empty:
                predicted_high = float(prediction_df['high'].max())
                predicted_low = float(prediction_df['low'].min())

            # å°†é¢„æµ‹æ•°æ®è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            prediction_data_json = ""
            if prediction_df is not None and not prediction_df.empty:
                try:
                    prediction_data_json = prediction_df.to_json(orient='records')
                except:
                    prediction_data_json = "{}"
            else:
                prediction_data_json = "{}"

            # æž„å»ºæ’å…¥SQLï¼ˆå…¼å®¹PostgreSQLå’ŒSQLiteï¼‰
            if db_config.db_type == 'postgresql':
                query = '''
                    INSERT INTO predictions (
                        timestamp, instrument, current_price, predicted_price,
                        price_change, price_change_pct, predicted_high, predicted_low,
                        volatility, trend_direction, lookback_hours, pred_hours,
                        temperature, top_p, sample_count, prediction_data
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                '''
            else:
                query = '''
                    INSERT INTO predictions (
                        timestamp, instrument, current_price, predicted_price,
                        price_change, price_change_pct, predicted_high, predicted_low,
                        volatility, trend_direction, lookback_hours, pred_hours,
                        temperature, top_p, sample_count, prediction_data
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                '''

            params_tuple = (
                report['timestamp'].isoformat(),
                report['instrument'],
                stats.get('current_price', 0),
                stats.get('predicted_price_end', 0),
                stats.get('price_change', 0),
                stats.get('price_change_pct', 0),
                predicted_high,
                predicted_low,
                stats.get('volatility', 0),
                stats.get('trend_direction', 'unknown'),
                report['lookback_hours'],
                report['pred_hours'],
                params.get('temperature', 1.0),
                params.get('top_p', 0.9),
                params.get('sample_count', 1),
                prediction_data_json
            )

            execute_query(query, params_tuple)
            self.logger.info(f"âœ… é¢„æµ‹ç»“æžœå·²ä¿å­˜åˆ°æ•°æ®åº“")

        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜é¢„æµ‹ç»“æžœå¤±è´¥: {e}")
    
    def save_actual_price(self, timestamp: datetime, instrument: str, price: float, volume: float):
        """ä¿å­˜å®žé™…ä»·æ ¼æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO actual_prices (timestamp, instrument, price, volume)
                VALUES (?, ?, ?, ?)
            ''', (timestamp.isoformat(), instrument, price, volume))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å®žé™…ä»·æ ¼å¤±è´¥: {e}")
    
    def log_system_event(self, level: str, message: str, details: str = None):
        """è®°å½•ç³»ç»Ÿäº‹ä»¶"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO system_logs (timestamp, level, message, details)
                VALUES (?, ?, ?, ?)
            ''', (datetime.now().isoformat(), level, message, details))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            self.logger.error(f"âŒ è®°å½•ç³»ç»Ÿäº‹ä»¶å¤±è´¥: {e}")
    
    def run_prediction_cycle(self):
        """æ‰§è¡Œä¸€æ¬¡é¢„æµ‹å‘¨æœŸ"""
        try:
            self.logger.info("ðŸ”„ å¼€å§‹æ–°çš„é¢„æµ‹å‘¨æœŸ")
            
            # èŽ·å–é¢„æµ‹
            report = self.prediction_service.get_prediction(
                lookback_hours=self.lookback_hours,
                pred_hours=self.pred_hours,
                temperature=self.temperature,
                top_p=self.top_p,
                sample_count=self.sample_count
            )
            
            # ä¿å­˜é¢„æµ‹ç»“æžœ
            self.save_prediction(report)
            
            # ä¿å­˜å½“å‰å®žé™…ä»·æ ¼
            current_data = report['historical_data'].iloc[-1]
            self.save_actual_price(
                current_data['timestamps'],
                report['instrument'],
                current_data['close'],
                current_data['volume']
            )
            
            # æ‰“å°ç®€åŒ–çš„é¢„æµ‹æŠ¥å‘Š
            self.print_brief_report(report)
            
            # è®°å½•ç³»ç»Ÿäº‹ä»¶
            self.log_system_event(
                "INFO", 
                f"é¢„æµ‹å‘¨æœŸå®Œæˆ - å½“å‰ä»·æ ¼: ${report['statistics']['current_price']:,.2f}, "
                f"é¢„æµ‹ä»·æ ¼: ${report['statistics']['predicted_price_end']:,.2f}"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ é¢„æµ‹å‘¨æœŸæ‰§è¡Œå¤±è´¥: {e}")
            self.log_system_event("ERROR", f"é¢„æµ‹å‘¨æœŸå¤±è´¥: {str(e)}")
    
    def print_brief_report(self, report: Dict[str, Any]):
        """æ‰“å°ç®€åŒ–çš„é¢„æµ‹æŠ¥å‘Š"""
        stats = report['statistics']
        timestamp = report['timestamp'].strftime('%Y-%m-%d %H:%M:%S')
        
        print(f"\n{'='*50}")
        print(f"ðŸ”® Kronosé¢„æµ‹æ›´æ–° - {timestamp}")
        print(f"{'='*50}")
        print(f"ðŸ’° å½“å‰ä»·æ ¼: ${stats.get('current_price', 0):,.2f}")
        print(f"ðŸ”® é¢„æµ‹ä»·æ ¼: ${stats.get('predicted_price_end', 0):,.2f}")
        print(f"ðŸ“ˆ ä»·æ ¼å˜åŒ–: {stats.get('price_change_pct', 0):+.2f}%")
        print(f"ðŸ“Š è¶‹åŠ¿æ–¹å‘: {stats.get('trend_direction', 'unknown').upper()}")
        print(f"â° ä¸‹æ¬¡æ›´æ–°: {(datetime.now() + timedelta(minutes=self.prediction_interval)).strftime('%H:%M:%S')}")
        print(f"{'='*50}\n")
    
    def start(self):
        """å¯åŠ¨æŒç»­é¢„æµ‹"""
        if self.is_running:
            self.logger.warning("âš ï¸ è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­")
            return
        
        self.logger.info("ðŸš€ å¯åŠ¨æŒç»­é¢„æµ‹è°ƒåº¦å™¨")
        
        # é…ç½®å®šæ—¶ä»»åŠ¡
        schedule.clear()
        schedule.every(self.prediction_interval).minutes.do(self.run_prediction_cycle)
        
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡é¢„æµ‹
        self.run_prediction_cycle()
        
        # å¯åŠ¨è°ƒåº¦å™¨çº¿ç¨‹
        self.is_running = True
        self.scheduler_thread = threading.Thread(target=self._run_scheduler, daemon=True)
        self.scheduler_thread.start()
        
        self.logger.info(f"âœ… è°ƒåº¦å™¨å·²å¯åŠ¨ï¼Œæ¯ {self.prediction_interval} åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡é¢„æµ‹")
    
    def _run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å™¨ä¸»å¾ªçŽ¯"""
        while self.is_running:
            try:
                schedule.run_pending()
                time.sleep(1)
            except Exception as e:
                self.logger.error(f"âŒ è°ƒåº¦å™¨è¿è¡Œå¼‚å¸¸: {e}")
                self.log_system_event("ERROR", f"è°ƒåº¦å™¨å¼‚å¸¸: {str(e)}")
                time.sleep(10)  # å¼‚å¸¸åŽç­‰å¾…10ç§’å†ç»§ç»­
    
    def stop(self):
        """åœæ­¢æŒç»­é¢„æµ‹"""
        if not self.is_running:
            self.logger.warning("âš ï¸ è°ƒåº¦å™¨æœªåœ¨è¿è¡Œ")
            return
        
        self.logger.info("ðŸ›‘ åœæ­¢æŒç»­é¢„æµ‹è°ƒåº¦å™¨")
        self.is_running = False
        
        if self.scheduler_thread and self.scheduler_thread.is_alive():
            self.scheduler_thread.join(timeout=5)
        
        schedule.clear()
        self.logger.info("âœ… è°ƒåº¦å™¨å·²åœæ­¢")
    
    def get_recent_predictions(self, limit: int = 10) -> pd.DataFrame:
        """èŽ·å–æœ€è¿‘çš„é¢„æµ‹ç»“æžœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            query = '''
                SELECT timestamp, current_price, predicted_price, price_change_pct, 
                       trend_direction, volatility
                FROM predictions 
                ORDER BY timestamp DESC 
                LIMIT ?
            '''
            
            df = pd.read_sql_query(query, conn, params=(limit,))
            conn.close()
            
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ èŽ·å–é¢„æµ‹åŽ†å²å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_prediction_accuracy(self, hours_back: int = 24) -> Dict[str, float]:
        """è®¡ç®—é¢„æµ‹å‡†ç¡®æ€§"""
        try:
            conn = sqlite3.connect(self.db_path)
            
            # èŽ·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„é¢„æµ‹å’Œå®žé™…ä»·æ ¼
            cutoff_time = (datetime.now() - timedelta(hours=hours_back)).isoformat()
            
            query = '''
                SELECT p.timestamp, p.predicted_price, p.price_change_pct as pred_change,
                       a.price as actual_price
                FROM predictions p
                LEFT JOIN actual_prices a ON 
                    datetime(p.timestamp, '+' || p.pred_hours || ' hours') = a.timestamp
                WHERE p.timestamp > ?
                AND a.price IS NOT NULL
            '''
            
            df = pd.read_sql_query(query, conn, params=(cutoff_time,))
            conn.close()
            
            if df.empty:
                return {"accuracy": 0.0, "mae": 0.0, "samples": 0}
            
            # è®¡ç®—å‡†ç¡®æ€§æŒ‡æ ‡
            df['actual_change'] = (df['actual_price'] - df['predicted_price']) / df['predicted_price'] * 100
            df['error'] = abs(df['pred_change'] - df['actual_change'])
            
            accuracy = {
                "mae": df['error'].mean(),  # å¹³å‡ç»å¯¹è¯¯å·®
                "rmse": (df['error'] ** 2).mean() ** 0.5,  # å‡æ–¹æ ¹è¯¯å·®
                "samples": len(df),
                "direction_accuracy": (
                    (df['pred_change'] > 0) == (df['actual_change'] > 0)
                ).mean() * 100  # æ–¹å‘é¢„æµ‹å‡†ç¡®çŽ‡
            }
            
            return accuracy
            
        except Exception as e:
            self.logger.error(f"âŒ è®¡ç®—é¢„æµ‹å‡†ç¡®æ€§å¤±è´¥: {e}")
            return {"accuracy": 0.0, "mae": 0.0, "samples": 0}


def create_prediction_scheduler(okx_config: OKXConfig, trading_config: TradingConfig, 
                              db_path: str = "./data/predictions.db", device: str = "cpu") -> PredictionScheduler:
    """åˆ›å»ºé¢„æµ‹è°ƒåº¦å™¨å®žä¾‹"""
    return PredictionScheduler(okx_config, trading_config, db_path, device)
